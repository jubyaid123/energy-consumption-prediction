{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/shepard_energy_consumption.xlsx')\n",
    "data.rename(columns={'CUNY City College of New York - 2018-09-01 -> 2023-08-31': 'Timestamp'}, inplace=True)\n",
    "data.drop(data.index[0], inplace=True)\n",
    "data.rename(columns={'12785711': 'Meter1'}, inplace=True)\n",
    "data.rename(columns={'12785712': 'Meter2'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Meter1</th>\n",
       "      <th>Meter2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01 01:00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>217.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-01 02:00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-01 03:00:00</td>\n",
       "      <td>126</td>\n",
       "      <td>216.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01 04:00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-09-01 05:00:00</td>\n",
       "      <td>122.5</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp Meter1 Meter2\n",
       "1  2018-09-01 01:00:00    124  217.5\n",
       "2  2018-09-01 02:00:00    124    218\n",
       "3  2018-09-01 03:00:00    126  216.5\n",
       "4  2018-09-01 04:00:00    124    216\n",
       "5  2018-09-01 05:00:00  122.5    219"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "data.set_index('Timestamp', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meter1</th>\n",
       "      <th>Meter2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-01 01:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>217.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01 02:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01 03:00:00</th>\n",
       "      <td>126</td>\n",
       "      <td>216.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01 04:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01 05:00:00</th>\n",
       "      <td>122.5</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Meter1 Meter2\n",
       "Timestamp                        \n",
       "2018-09-01 01:00:00    124  217.5\n",
       "2018-09-01 02:00:00    124    218\n",
       "2018-09-01 03:00:00    126  216.5\n",
       "2018-09-01 04:00:00    124    216\n",
       "2018-09-01 05:00:00  122.5    219"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for Meter1 and Meter2 separately\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data_meter1 = scaler1.fit_transform(data['Meter1'].values.reshape(-1, 1))\n",
    "scaled_data_meter2 = scaler2.fit_transform(data['Meter2'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataset for LSTM\n",
    "# stores values in array X that will be used to predict value in correspending index in Y\n",
    "# first iteration\n",
    "# 0-23 values stored in X, 24th value stored in Y(target value)\n",
    "# second iteration \n",
    "# 1-24 stored in X, 25th value stored in Y\n",
    "def create_dataset(dataset1, dataset2, look_back):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset1) - look_back - 1):\n",
    "        a1 = dataset1[i:(i + look_back), 0]\n",
    "        a2 = dataset2[i:(i + look_back), 0]\n",
    "        X.append(np.concatenate((a1, a2), axis=0))  # Combine both Meter1 and Meter2 data\n",
    "        Y.append(np.concatenate((dataset1[i + look_back, 0], dataset2[i + look_back, 0]), axis=0))  # Predict both Meter1 and Meter2\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jubya\\Programs\\NasaResearch\\Meter_energy_predection_take_2\\meter2_output_lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating the dataset suitable for LSTM\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Creating the dataset suitable for LSTM\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X, Y \u001b[39m=\u001b[39m create_dataset(scaled_data_meter1, scaled_data_meter2, look_back)\n",
      "\u001b[1;32mc:\\Users\\jubya\\Programs\\NasaResearch\\Meter_energy_predection_take_2\\meter2_output_lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     a2 \u001b[39m=\u001b[39m dataset2[i:(i \u001b[39m+\u001b[39m look_back), \u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     X\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate((a1, a2), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))  \u001b[39m# Combine both Meter1 and Meter2 data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     Y\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mconcatenate((dataset1[i \u001b[39m+\u001b[39;49m look_back, \u001b[39m0\u001b[39;49m], dataset2[i \u001b[39m+\u001b[39;49m look_back, \u001b[39m0\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))  \u001b[39m# Predict both Meter1 and Meter2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jubya/Programs/NasaResearch/Meter_energy_predection_take_2/meter2_output_lstm.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(X), np\u001b[39m.\u001b[39marray(Y)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "# Creating the dataset suitable for LSTM\n",
    "# Creating the dataset suitable for LSTM\n",
    "X, Y = create_dataset(scaled_data_meter1, scaled_data_meter2, look_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reshaping input to be [samples, time steps, features]\n",
    "X_1 = np.reshape(X_1, (X_1.shape[0], X_1.shape[1], 1))\n",
    "X_2 = np.reshape(X_2, (X_2.shape[0], X_2.shape[1], 1))\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "train_size = int(len(X_1) * 0.8)\n",
    "X_1_train, X_1_test = X_1[:train_size], X_1[train_size:]\n",
    "Y_1_train, Y_test = Y_1[:train_size], Y_1[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_1.shape, X_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Building the LSTM network\n",
    "## sequential model means layers are a linear stack where layers can be added one after another \n",
    "model = Sequential()\n",
    "## first layer has 50 neurons, inpputshape(time steps, features) return_sequences because there is another layer\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# second and last layer \n",
    "model.add(LSTM(50, return_sequences= True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "# output for final predictin Dense means the neuron is fully connected with previous neurons\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=64, verbose=1)\n",
    "#model starts processing data in X_train and amkes predictions for y_train adjusts every epoch based on MSE thus training it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model.predict(X_train)\n",
    "# model makes prediction for energy output based on previously seen data\n",
    "#train_predict should predict the valyes in Y_train\n",
    "test_predict = model.predict(X_test)\n",
    "# model makes predictions based of new data\n",
    "# test_predict should predict the valyes in Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inverting predictions to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "Y_train_inv = scaler.inverse_transform([Y_train])\n",
    "Y_test_inv = scaler.inverse_transform([Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_inv.shape\n",
    "print(Y_train_inv[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating RMSE\n",
    "train_rmse = np.sqrt(mean_squared_error(Y_train_inv[0], train_predict[:,0]))\n",
    "test_rmse = np.sqrt(mean_squared_error(Y_test_inv[0], test_predict[:,0]))\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(data['Meter1'][-len(Y_test):].index, Y_test_inv[0], label='Actual')\n",
    "plt.plot(data['Meter1'][-len(Y_test):].index, test_predict[:, 0], label='Predicted', alpha = 0.3)\n",
    "plt.title('Meter Energy Output Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Meter1'][-len(Y_test):].index, test_predict[:, 0], label='Predicted')\n",
    "plt.title('Meter Energy Output Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Energy Output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_data_week = data['Meter1'][-24:]\n",
    "scaled_recent_data_week = scaler.transform(recent_data_week.values.reshape(-1,1))\n",
    "print(scaled_recent_data_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(recent_data_week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_week = np.reshape(scaled_recent_data_week, (1, 24, 1))\n",
    "predictions_week = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7*24):  # Loop for 7 days 24 hours a day \n",
    "    daily_prediction_scaled = model.predict(sequence_week)\n",
    "    daily_prediction = scaler.inverse_transform(daily_prediction_scaled)\n",
    "    predictions_week.append(daily_prediction[0, 0])\n",
    "    \n",
    "    # Update the sequence: roll and append the new prediction\n",
    "    sequence_week = np.roll(sequence_week, -1)\n",
    "    sequence_week[0, -1, 0] = daily_prediction_scaled[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions_week))\n",
    "print(predictions_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and end dates\n",
    "start_date = pd.to_datetime('2023-09-01 01:00')\n",
    "end_date = pd.to_datetime('2023-09-08 00:00')  \n",
    "\n",
    "# Generate a list of hourly timestamps\n",
    "timestamps = pd.date_range(start=start_date, end=end_date, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(timestamps))\n",
    "print(len(predictions_week))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5)) \n",
    "plt.plot(timestamps, predictions_week, label='Predicted Energy Output')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Output')\n",
    "plt.title('Hourly Energy Output Predictions from 2023-09-01 to 2023-09-07')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_week[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_data_month = data['Meter1'][-24:]\n",
    "scaled_recent_data_month = scaler.transform(recent_data_month.values.reshape(-1,1))\n",
    "sequence_month = np.reshape(scaled_recent_data_month, (1,24,1))\n",
    "print(scaled_recent_data_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_month = []\n",
    "for i in range(30 * 24):  # 30 days * 24 hours\n",
    "    hourly_prediction_scaled = model.predict(sequence_month)\n",
    "    hourly_prediction = scaler.inverse_transform(hourly_prediction_scaled)\n",
    "    predictions_month.append(hourly_prediction[0, 0])\n",
    "\n",
    "    sequence_month = np.roll(sequence_month, -1)\n",
    "    sequence_month[0, -1, 0] = hourly_prediction_scaled[0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_month = pd.to_datetime('2023-09-01 00:00')\n",
    "end_date_month = pd.to_datetime('2023-09-30 23:00')\n",
    "timestamps_month = pd.date_range(start=start_date_month, end=end_date_month, freq='H')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(timestamps_month))\n",
    "print(len(predictions_month))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(timestamps_month, predictions_month, label='Predicted Energy Output')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Output')\n",
    "plt.title('Hourly Energy Output Predictions for September 2023')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('week_predictions.csv', 'w', newline='')as file:\n",
    "    writer = csv.writer(file)\n",
    "    for prediction in predictions_week:\n",
    "        writer.writerow([prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
